from nltk.stem.porter import PorterStemmer
from nltk.tokenize import RegexpTokenizer

import gensim
from gensim import corpora, models
from stop_words import get_stop_words

tokenizer = RegexpTokenizer(r'\w+')

# create English stop words list
en_stop = get_stop_words('es')

# Create p_stemmer of class PorterStemmer
p_stemmer = PorterStemmer()
    
# create sample documents

tweets = ['@sweets_emotions en todos los centros de acopio muchas gracias por ayudar',
 '#fuerzam√©xico üá≤ üáΩ #rescateprimero üôè üèª',
 'jam√°s olvidar√© todo lo que he visto hoy mi gente mi pa√≠s si podemos salir adelante #fuerzamexico',
 'en chatapas estaremos ofreciendo comida gratis a voluntarios y afectados por el sismo si alguien desea ayudar los esperamos',
 '#fuerzam√©xico #noshemoslevantadodepeores #sisepuede üá≤ üáΩ en coyoac√°n',
 '22/09 20:20 #voluntarios entrada plaza galer√≠as en bicis para ir de acopio en acopio para lo que se necesiten 10 a 10:30 pm #ayudacdmx',
 'enhorabuena la banda de heavy metal @slipknot don√≥ medicamentos para los afectados del #sismo üëè üëè #mexico',
 'todas las redes de #wifi de #telmex #infinitum son abiertas a la comunidad con la contrase√±a 803261 #ayuda #sismo #fuerzamexico #cdmx',
 'urge escalera de 5 metros en derrumbe de escocia y gabriel mancera si conocen a alg√∫n vecino que tenga una l√°ncese para ac√° por fa',
 '#confirmado frida sof√≠a la ni√±a del #r√©bsamen habl√≥ con sus rescatistas y dice q habla con 5 compa√±eros m√°s ojal√° as√≠ sea üôè #fuerzam√©xico',
 'su necesitas ayuda para encontrar personas comunicate al 55 3993 9549',
 'centro de acopio se encuentra en la explanada del @parquemexico @lacondesa_',
 'raza hay fugas de gas en √°reas cercanas a centro de acopio #parquemexico #brigadistas usen tapabocas no fumen y apaguen celulares #rt',
 'sismo se sinti√≥ duro',
 'despliega @gobcdmx 50 mil elementos en labores de rescate y atenci√≥n por sismo de 7.1 grados en la escala de richter',
 'a√∫n hay trabajo que hacer #fuerzamexico #prayformexico',
 'por qu√© el gobierno de m√©xico no acept√≥ la ayuda del gobierno de suiza qu√© esconde eso qu√© protagonismos proteje #sismo',
 'hoy se suspenden actividades en el centro regional de cultura de toluca hasta nuevo aviso #fuerzamexico #mexicounido',
 'se necesitan herramientas v√≠veres y medicamentos en la col roma #verificado19s',
 'lo que importa es la uni√≥n y ayudar a los que nos necesitan #ayudacdmx #fuerzamexico',
 'y as√≠ se lleva m√©xico en la piel üá≤ üáΩ üíî #fuerzam√©xico',
 'üî¥ #actualizaci√≥n ‚ö° total 324 fallecidos por #sismo 19/09 17 #cdmx 186 #morelos 73 #puebla 45 #edom√©x 13 #guerrero 6 #oaxaca 1',
 'cuando le dan like o dan a poetuits se entorpece la ayuda dejen que pase un tiempo y ya rinden pleites√≠a o dan eco a influencers',
 '12 horas interminables hoy le doy asilo a mi familia ma√±ana salimos en ayuda a otras familias üôè üèª #fuerzam√©xico',
 '#m√©xicoest√°depie #mexicounido #ayudacdmx todos lo que puedan ayudar h√°ganlo por mas poco que sea todo es buena ayuda en estos momentos üíî',
 '#mexicanosunidos #fuerzam√©xico üôè ‚ù§',
 'el gobernador alfredo del mazo confirma al menos dos muertes en el estado de m√©xico por sismo de magnitud 7.1',
 '#ent√©rate informa condusef que suspende plazos y procedimientos tras sismo #abriendolaconversaci√≥n',
 '\U0001f91d el actor @diegoluna_ contin√∫a en el centro de acopio de lago de tanganica 67 en polanco \U0001f91d solicita tanques de ox',
 'ay√∫denme a encontrarlo por favor #sismo',
 'bien lo dec√≠a un tuit que le√≠ si ten√≠an hambre se hubieran acercado a un centro de acopio pidiendo ayuda #tuiterosvendidos',
 'se nota la diferente reacci√≥n de la gente con la #alertasismica :(',
 '#sntesolidario alista secc 44 durango envi√≥ de v√≠veres #ayudaciudadana por #temblor al magisterio y sociedad',
 'es tan conmovedor ver el apoyo que recibe m√©xico de otros pa√≠ses mil gracias #fuerzam√©xico #m√©xicodepie',
 'aqu√≠ se necesitan v√≠veres']

doc_a = "Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother."
doc_b = "My mother spends a lot of time driving my brother around to baseball practice."
doc_c = "Some health experts suggest that driving may cause increased tension and blood pressure."
doc_d = "I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better."
doc_e = "Health professionals say that brocolli is good for your health." 

# compile sample documents into a list
doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]

# list for tokenized documents in loop
texts = []

# loop through document list
for i in tweets:
	# clean and tokenize document string	
	raw = i.lower()
	tokens = tokenizer.tokenize(raw)
	# remove stop words from tokens
	stopped_tokens = [i for i in tokens if not i in en_stop]
	
	# stem tokens
	stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]
	
	# add tokens to list
	texts.append(stemmed_tokens)

# turn our tokenized documents into a id <-> term dictionary
dictionary = corpora.Dictionary(texts)
    
# convert tokenized documents into a document-term matrix
corpus = [dictionary.doc2bow(text) for text in texts]

# generate LDA model
ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=50, id2word = dictionary, passes=20)

print(ldamodel)

print(ldamodel.print_topics(num_topics=2, num_words=4))
